# following commands that local computer will have to run (in order)
#1. Command to create stack:
# aws cloudformation create-stack --stack-name NewStackName --template-body file://path/to/your/existing-template.yaml --region us-west-2
# 2. Command that will upload local csv file onto existing s3 bucket
# aws s3 cp /path/to/your/csvfile.csv s3://your-existing-bucket-name/csvfile.csv

# local computer will need credentials to run above

# template plans:
# 1. contains services that will run once and will stay; includes: output s3 bucket, security group, iam roles, input bucket
# 2. contains services that will run everytime; includes: ec2 instance

# to-do:
#EC2 launch role
#add a security group



Parameters:
  CSVFile:
    Type: String
    Description: Path to the csv file
Resources:
  Vpc:
    Type: AWS::EC2::VPC
    Properties:
      # ask about proper ip addy
      CidrBlock: 10.0.0.0/16
      EnableDnsSupport: true
      EnableDnsHostnames: true

  InternetGateway:
    Type: AWS::EC2::InternetGateway
  
  # do we need a transit gateway? 
  #(allows you to interconnect multiple VPCs and VPN connections into a single gateway)
  VpcGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref Vpc
      InternetGatewayId: !Ref InternetGateway

  PublicSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref Vpc
      CidrBlock: 10.0.0.0/16
      MapPublicIpOnLaunch: true

  PrivateSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVpc
      CidrBlock: 10.0.0.0/16

  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref Vpc

  PublicRoute:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  PublicSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet
      RouteTableId: !Ref PublicRouteTable

  PrivateRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref MyVpc

  PrivateRouteToNAT:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref MyNATGateway

  PrivateSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PrivateSubnet
      RouteTableId: !Ref PrivateRouteTable
  
  MyNATGatewayEIP:
    Type: AWS::EC2::EIP

  MyNATGateway:
    Type: AWS::EC2::NatGateway
    Properties:
      SubnetId: !Ref PublicSubnet
      AllocationId: !GetAtt MyNATGatewayEIP.AllocationId
  
  #Outputs:
  # VpcId:
  #   Value: !Ref MyVpc
  # PublicSubnetId:
  #   Value: !Ref PublicSubnet
  # PrivateSubnetId:
  #   Value: !Ref PrivateSubnet
  # NATGatewayId:
  #   Value: !Ref MyNATGateway
  
  InputS3:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: csm-match-mock-data
    DeletionPolicy: Delete
    Region: us-west-2

  OutputS3:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: csm-match-mock-data-matched
    DeletionPolicy: Retain
    Region: us-west-2
  MyLifecycleConfiguration:
    Type: AWS::S3::BucketLifecycleConfiguration
    Properties:
      Bucket: !Ref OutputS3
      LifecycleConfiguration:
        Rules:
          - Id: Retain3Days
            Status: Enabled
            ExpirationInDays: 3

  # based on how many times we think the instance will have to run per quarter
  # option 1: to have instance terminate each time so bash runs everytime
  # option 2: find a way for instance to re-run userdata bash script w/o termination
  MyInstance:
    Type: AWS::EC2::Instance
    Properties:
      KeyName: !Ref KeyName
      SecurityGroups:
      - !Ref logical name of AWS::EC2::SecurityGroup resource
      UserData:
      #use aws s3 cp s3://bucketname/filename /path/to/file to get files from s3 and not github for csv later
      #add credential section for github
      #need secrets manager
      #IAM roles for EC2 instance secret manager
      #IAM roles for EC2 instance S3
      #IAM roles for S3 to grab from EC2 instance
      #add statement to prevent delete of S3 bucket
      #cloudwatch logs if error
        Fn::Base64: !Sub |
          #!/bin/bash -xe
          yum update -y aws-cfn-bootstrap
          yum install awscli -y
          aws s3 cp 
          wget https://github.com/dconroybeam/CSM-Match/blob/e69c72947a5d55c09dd5dc9be6a802712831f3c6/Mock%20Data/CSM%20Match%20Mock%20Matching%20Script%2020230720.Rmd
          wget https://github.com/dconroybeam/CSM-Match/blob/e69c72947a5d55c09dd5dc9be6a802712831f3c6/Mock%20Data/CSM%20Match%20Mock%20Data%2020230720%20164351.csv
          rscript CSM%20Match%20Mock%20Matching%20Script%2020230720.Rmd CSM%20Match%20Mock%20Data%2020230720%20164351.csv
          current_date=$(date +"%Y.%m.%d")
          current_time=$(date +"%H.%M.%S")
          file_name_base="CSM MATCH Mock Data MATCHED"
          file_name="${file_name_base}_${current_date}_${current_time}.csv"
          aws s3 cp "$file_name" s3://csm-match-mock-data-matched/
          aws cloudformation delete-stack --stack-name POCTemplate1
      InstanceType: m1.small
      AvailabilityZone: us-east-1a
      ImageId: ami-0ff8a91507f77f867