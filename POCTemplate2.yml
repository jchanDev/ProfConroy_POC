# stack with only ec2 instance

# based on how many times we think the instance will have to run per quarter
  # option 1: to have instance terminate each time so bash runs everytime
  # option 2: find a way for instance to re-run userdata bash script w/o termination

Parameters:
  EC2InstanceRoleArn:
    Type: String
    Description: ARN of the EC2 instance IAM role

Resources:
  MySecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: My EC2 instance security group
      VpcId: 'vpc-00b9bd3a6d70475f1'
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22  # SSH port for instance management
          ToPort: 22
          CidrIp: 10.226.19.192/26

  MyInstance:
    Type: AWS::EC2::Instance
    Properties:
     # KeyName: !Ref KeyName
      SubnetId: 'subnet-09c627ce914a28786'
      SecurityGroupIds:
      - !Ref MySecurityGroup
      IamInstanceProfile: !Ref EC2InstanceRoleArn
      UserData:
      #use aws s3 cp s3://bucketname/filename /path/to/file to get files from s3 and not github for csv later
      #add credential section for github
      #need secrets manager
      #IAM roles for EC2 instance secret manager
      #IAM roles for EC2 instance S3
      #IAM roles for S3 to grab from EC2 instance
      #add statement to prevent delete of S3 bucket
      #cloudwatch logs if error
        Fn::Base64: !Sub |
          #!/bin/bash -xe
          yum update -y aws-cfn-bootstrap
          yum install awscli -y
          wget https://github.com/kpancha1/POC-test-file-R/blob/main/testfile.R
          inputFile=$(aws s3 cp s3://InputS3BucketPOC2023/testfile.R -)
          if [[ -n "$inputFile" ]]; then
            echo "File content:" > worked.txt
            echo "$inputFile" >> worked.txt
            aws s3 cp worked.txt s3://OutputS3BucketPOC2023/
          else
            echo "Failed to retrieve file content." > error.txt
            aws s3 cp error.txt s3://OutputS3BucketPOC2023/
          fi

         
      InstanceType: m1.small
      AvailabilityZone: us-east-1a
      ImageId: ami-0fa77410ef95ac0bb


      #  wget https://github.com/dconroybeam/CSM-Match/blob/e69c72947a5d55c09dd5dc9be6a802712831f3c6/Mock%20Data/CSM%20Match%20Mock%20Data%2020230720%20164351.csv
      #     wget https://github.com/dconroybeam/CSM-Match/blob/e69c72947a5d55c09dd5dc9be6a802712831f3c6/Mock%20Data/CSM%20Match%20Mock%20Matching%20Script%2020230720.Rmd
      #     Rscript CSM%20Match%20Mock%20Matching%20Script%2020230720.Rmd CSM%20Match%20Mock%20Data%2020230720%20164351.csv
      #     current_date=$(date +"%Y.%m.%d")
      #     current_time=$(date +"%H.%M.%S")
      #     file_name_base="CSM MATCH Mock Data MATCHED"
      #     file_name="${file_name_base}_${current_date}_${current_time}.csv"
      #     if [[ ! -e "$file_name" ]]; then
      #       echo "error" > error.txt
      #       aws s3 cp error.txt s3://csm-match-mock-data-matched/
      #     else
      #       aws s3 cp "$file_name" s3://csm-match-mock-data-matched/
      #     fi